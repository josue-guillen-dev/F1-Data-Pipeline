# ğŸï¸ F1 Data Pipeline: ETL & AnÃ¡lisis Automatizado

> **Estado:** Completado v1.0
> **Rol:** Data Analyst / Data Engineer Junior

## ğŸ“‹ DescripciÃ³n del Proyecto
Este proyecto simula un entorno de **IngenierÃ­a de Datos real**.
El objetivo fue construir un **Pipeline ETL (Extract, Transform, Load)** automatizado que:
1.  **Extrae** resultados histÃ³ricos de FÃ³rmula 1 desde una base de datos SQL.
2.  **Transforma** y limpia los datos usando Python (Pandas), eliminando errores y nulos.
3.  **Carga** los resultados generando reportes de negocio visuales automÃ¡ticamente.

El sistema reemplaza el anÃ¡lisis manual en Excel por un script ejecutable que estandariza la calidad de los datos.

## âš™ï¸ Â¿CÃ³mo funciona el flujo?
El dato viaja de la siguiente manera:
`[Base de Datos SQL] --> [Script de Python] --> [Reporte Final (Excel + PNG)]`

## ğŸš€ Funcionalidades Clave
* **ModularizaciÃ³n:** CÃ³digo separado en lÃ³gica de negocio (`f1_tools.py`) y ejecuciÃ³n (`main.py`) para ser escalable.
* **ConexiÃ³n SQL DinÃ¡mica:** Consultas adaptables segÃºn la elecciÃ³n del usuario (Pilotos vs. Constructores).
* **Limpieza Automatizada:** Tratamiento de valores nulos (`NaN`) y conversiÃ³n de tipos de datos (Casting).
* **ExportaciÃ³n Inteligente:** Los archivos se guardan automÃ¡ticamente en carpetas organizadas.

## ğŸ› ï¸ TecnologÃ­as Usadas
* **Lenguaje:** Python 3.10+
* **LibrerÃ­as:** Pandas, Matplotlib, SQLite3.
* **Base de Datos:** SQLite / SQL Standard.
* **Control de Versiones:** Git.

## ğŸ“‚ Estructura del Proyecto
* `data/`: Fuente de verdad (DB y CSVs crudos).
* `export/`: Destino de reportes generados.
* `f1_tools.py`: MÃ³dulo de herramientas (Funciones ETL).
* `main.py`: Script principal.
* `README.md`: DocumentaciÃ³n.

## ğŸ“Š Resultado Visual

![GrÃ¡fico del Reporte](export/reporte_top10_pilotos.png)
![GrÃ¡fico del Reporte](export/reporte_top10_constructores.png)

*(Estos grÃ¡ficos se actualizan automÃ¡ticamente al correr el script)*

---
**Autor:** JosuÃ© - Analista de Datos en formaciÃ³n ğŸ¦